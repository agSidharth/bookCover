{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        pass\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-28T16:02:06.031596Z","iopub.execute_input":"2022-11-28T16:02:06.032214Z","iopub.status.idle":"2022-11-28T16:02:19.840927Z","shell.execute_reply.started":"2022-11-28T16:02:06.032109Z","shell.execute_reply":"2022-11-28T16:02:19.839889Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Importing libraries\nimport numpy as np\nimport pandas as pd\nimport os\nimport torch\nfrom torch.utils.data import Dataset\nfrom transformers import TrainingArguments, Trainer\nfrom transformers import BertTokenizer, BertForSequenceClassification\nfrom torch.utils.data import DataLoader\nfrom transformers import EarlyStoppingCallback\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n\nSEED = 661077\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\n\nMAX_LENGTH = 75\nNUM_LABELS = 30\nmodelName = \"bert-large-uncased\"\n\nEPOCHS = 10\nEPSILON = 1e-4\nDEBUG = True \nLR = 2.6*0.00001\nMOMENTUM = 0.9\n\nthisDevice = 'cuda:0' if torch.cuda.is_available() else 'cpu'\ndevice = torch.device(thisDevice)\nprint(\"The device in use is : \"+thisDevice)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T16:02:19.843160Z","iopub.execute_input":"2022-11-28T16:02:19.843585Z","iopub.status.idle":"2022-11-28T16:02:28.746187Z","shell.execute_reply.started":"2022-11-28T16:02:19.843548Z","shell.execute_reply":"2022-11-28T16:02:28.745064Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"The device in use is : cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"# inintializing pretrained bert and its tokenizer\ntokenizer = BertTokenizer.from_pretrained(modelName)\nmodel = BertForSequenceClassification.from_pretrained(modelName, num_labels=NUM_LABELS)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T16:02:28.749547Z","iopub.execute_input":"2022-11-28T16:02:28.750487Z","iopub.status.idle":"2022-11-28T16:03:22.526436Z","shell.execute_reply.started":"2022-11-28T16:02:28.750452Z","shell.execute_reply":"2022-11-28T16:03:22.525558Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d798dc9ee081452a866c25ca631a1e92"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df57e25861364d29be6dedae20dfb817"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d59978d54834eb1a11e5d7fd71c901a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.25G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75b19e06805248a38c27273b9c2a4f9d"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Function for data class\nclass bookDataset(Dataset):\n    def __init__(self,path_to_x,path_to_y,dataDir,tokenizer):\n        \n        self.temp_titles = list(pd.read_csv(os.path.join(dataDir,path_to_x)).iloc[:,2].values)\n        self.titles = tokenizer(self.temp_titles,padding = True,truncation = True,max_length = MAX_LENGTH)\n        \n        self.labels = None\n        if path_to_y!=\"\":\n            self.labels = list(pd.read_csv(os.path.join(dataDir,path_to_y)).iloc[:,1].values)\n    \n    def __len__(self):\n        return len(self.titles[\"input_ids\"])\n    \n    def __getitem__(self,idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.titles.items()}\n        if self.labels!=None:\n            item[\"labels\"] = torch.tensor(self.labels[idx])\n        return item\n\ntrainDataset = bookDataset(\"train_x.csv\",\"train_y.csv\",\"/kaggle/input/col774-2022/\",tokenizer)\ntestDataset = bookDataset(\"non_comp_test_x.csv\",\"non_comp_test_y.csv\",\"/kaggle/input/col774-2022/\",tokenizer)\ntrainloader = DataLoader(trainDataset,batch_size = 64,shuffle = True)\ntestloader = DataLoader(testDataset,batch_size = 64,shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T16:03:22.529171Z","iopub.execute_input":"2022-11-28T16:03:22.529861Z","iopub.status.idle":"2022-11-28T16:03:40.404297Z","shell.execute_reply.started":"2022-11-28T16:03:22.529821Z","shell.execute_reply":"2022-11-28T16:03:40.403293Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"loss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)\n\nmodel = model.to(device)\n\n# Testing on the test data\ndef calAccuracy(model,dataloader,device):\n    correct = 0\n    total = 0\n    \n    torch.set_grad_enabled(False)\n    \n    for data in dataloader:\n        input_ids = data[\"input_ids\"].to(device)\n        attention_mask = data[\"attention_mask\"].to(device)\n        labels = data[\"labels\"].to(device)\n        \n        total += input_ids.size(0)\n        \n        outputs = model(input_ids,attention_mask = attention_mask,labels = labels)\n        predicted = torch.nn.functional.softmax(outputs[\"logits\"]).argmax(1)\n        correct += (predicted==labels).sum().item()\n        \n    torch.set_grad_enabled(True)\n    finalAcc = (correct*100)/total\n    print(\"The accuracy of the model : \"+str(finalAcc))\n    return finalAcc","metadata":{"execution":{"iopub.status.busy":"2022-11-28T16:03:40.405945Z","iopub.execute_input":"2022-11-28T16:03:40.406337Z","iopub.status.idle":"2022-11-28T16:03:45.932115Z","shell.execute_reply.started":"2022-11-28T16:03:40.406289Z","shell.execute_reply":"2022-11-28T16:03:45.931112Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# training model function\ndef trainModel(model,dataloader,loss_fn,optimizer,EPOCHS,EPSILON,device,PATH):\n    \n    last_loss = (np.inf)/2\n    max_valAcc = 0\n    \n    for epoch in range(EPOCHS):\n        this_loss = 0.0\n\n        for idx,data in enumerate(dataloader,0):\n            if(DEBUG and idx%100==0): \n                print(\"Iteration : \"+str(idx))\n#                 calAccuracy(model,testloader,device)\n            \n            input_ids = data[\"input_ids\"].to(device)\n            attention_mask = data[\"attention_mask\"].to(device)\n            labels = data[\"labels\"].to(device)\n            \n            optimizer.zero_grad()\n            output = model(input_ids,attention_mask = attention_mask,labels=labels)\n            loss = output[0]\n            loss.backward()\n            optimizer.step()\n\n            this_loss += loss\n        \n        this_loss = this_loss/len(dataloader)\n        #if(abs(this_loss-last_loss)<EPSILON): break\n        last_loss = this_loss\n        \n        print(\"Epoch : \"+str(epoch)+\", Loss ==> \"+str(last_loss))\n        print(\"Testing Accuracy ==>\")\n        \n        this_valAcc = calAccuracy(model,testloader,device)\n        if(this_valAcc>max_valAcc):\n            max_valAcc = this_valAcc\n            torch.save(model.state_dict(),PATH)\n            print(\"Model saved\")\n        \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-11-28T16:03:45.933545Z","iopub.execute_input":"2022-11-28T16:03:45.934551Z","iopub.status.idle":"2022-11-28T16:03:45.945012Z","shell.execute_reply.started":"2022-11-28T16:03:45.934511Z","shell.execute_reply":"2022-11-28T16:03:45.943798Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Running the loop\n\nPATH = \"/kaggle/working/Transformers.pth\"\ntrainModel(model,trainloader,loss_fn,optimizer,EPOCHS,EPSILON,device,PATH)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T16:03:45.946819Z","iopub.execute_input":"2022-11-28T16:03:45.947178Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Iteration : 0\nIteration : 100\nIteration : 200\n","output_type":"stream"}]},{"cell_type":"code","source":"# reloading the last saved(best) model\nmodel = BertForSequenceClassification.from_pretrained(modelName, num_labels=NUM_LABELS)\nmodel.load_state_dict(torch.load(PATH))\nmodel.to(device)\n\n\n# print(\"Training Accuracy ==>\"+str(calAccuracy(model,trainloader,device)))\n# print(\"Testing Accuracy ==>\"+str(calAccuracy(model,testloader,device)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compDataset = bookDataset(\"comp_test_x.csv\",\"\",\"/kaggle/input/col774-2022/\",tokenizer)\ncomploader = DataLoader(compDataset,batch_size = 64,shuffle = False)\n\n# printing the output dataframe to csv file\ndef outputToFile(model,dataloader,device,outFileName):\n    torch.set_grad_enabled(False)\n    \n    counter = 0\n    Ids = []\n    outputs = []\n    \n    for data in dataloader:\n        input_ids = data[\"input_ids\"].to(device)\n        attention_mask = data[\"attention_mask\"].to(device)\n        model_outputs = model(input_ids,attention_mask = attention_mask)\n        predicted = torch.nn.functional.softmax(model_outputs[\"logits\"]).argmax(1)\n        \n        for pred in predicted:\n            Ids.append(counter)\n            outputs.append(int(pred))\n            counter += 1\n        \n    torch.set_grad_enabled(True)\n    df = pd.DataFrame(list(zip(Ids,outputs)),columns = [\"Id\",\"Genre\"])\n    df.to_csv(outFileName,index=False)\n\noutputToFile(model,comploader,device,\"/kaggle/working/transformer_submission.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}