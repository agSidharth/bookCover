{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        pass\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-28T12:10:15.305019Z","iopub.execute_input":"2022-11-28T12:10:15.305798Z","iopub.status.idle":"2022-11-28T12:10:25.428236Z","shell.execute_reply.started":"2022-11-28T12:10:15.305699Z","shell.execute_reply":"2022-11-28T12:10:25.427093Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Importing libraries\nimport numpy as np\nimport pandas as pd\nimport os\nimport torch\nfrom torch.utils.data import Dataset\nfrom transformers import TrainingArguments, Trainer\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\n\nfrom torch.utils.data import DataLoader\nfrom transformers import EarlyStoppingCallback\nfrom PIL import Image\nimport torchvision.transforms as transforms\nfrom transformers import ViTFeatureExtractor,ViTModel,ViTConfig\nimport tqdm \n\nSEED = 661077\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\ntorch.cuda.manual_seed(SEED)\n\nMAX_LENGTH = 20\nNUM_LABELS = 30\nmodelName = \"bert-large-uncased\"\ncnn_modelName = 'google/vit-base-patch16-224-in21k'\n\nBERT_DIMENSION = 1024 if \"large\" in modelName else 768\nEPOCHS = 10\nEPSILON = 1e-4\nDEBUG = True \nLR = 2*0.00001\nMOMENTUM = 0.9\n\nBATCH_SIZE = 4\ngradAcc = 4\n\nthisDevice = 'cuda:0' if torch.cuda.is_available() else 'cpu'\ndevice = torch.device(thisDevice)\nprint(\"The device in use is : \"+thisDevice)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T12:10:25.429973Z","iopub.execute_input":"2022-11-28T12:10:25.430444Z","iopub.status.idle":"2022-11-28T12:10:31.632667Z","shell.execute_reply.started":"2022-11-28T12:10:25.430400Z","shell.execute_reply":"2022-11-28T12:10:31.630818Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"The device in use is : cuda:0\n","output_type":"stream"}]},{"cell_type":"code","source":"# inintializing pretrained bert and its tokenizer\ntokenizer = AutoTokenizer.from_pretrained(modelName)\nfeature_extractor = ViTFeatureExtractor.from_pretrained(cnn_modelName)\n\n# Function for data class\nclass bookDataset(Dataset):\n    def __init__(self,path_to_x,path_to_y,dataDir,tokenizer):\n        \n        self.images = pd.read_csv(os.path.join(dataDir,path_to_x))\n        self.img_dir = os.path.join(dataDir,\"images\",\"images\")\n        \n        self.temp_titles = list(pd.read_csv(os.path.join(dataDir,path_to_x)).iloc[:,2].values)\n        self.titles = tokenizer(self.temp_titles,padding = True,truncation = True,max_length = MAX_LENGTH)\n        \n        self.labels = None\n        if path_to_y!=\"\":\n            self.labels = list(pd.read_csv(os.path.join(dataDir,path_to_y)).iloc[:,1].values)\n    \n    def __len__(self):\n        return len(self.titles[\"input_ids\"])\n    \n    def __getitem__(self,idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.titles.items()}\n        if self.labels!=None:\n            item[\"labels\"] = torch.tensor(self.labels[idx])\n        \n        img_path = os.path.join(self.img_dir,self.images.iloc[idx,1])\n        thisImg = Image.open(img_path)\n        item[\"img\"] = feature_extractor(thisImg, return_tensors='pt')[\"pixel_values\"][0]\n        \n        return item\n\ntrainDataset = bookDataset(\"train_x.csv\",\"train_y.csv\",\"/kaggle/input/col774-2022/\",tokenizer)\ntestDataset = bookDataset(\"non_comp_test_x.csv\",\"non_comp_test_y.csv\",\"/kaggle/input/col774-2022/\",tokenizer)\ntrainloader = DataLoader(trainDataset,batch_size = BATCH_SIZE,shuffle = True)\ntestloader = DataLoader(testDataset,batch_size = BATCH_SIZE,shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T12:10:31.635761Z","iopub.execute_input":"2022-11-28T12:10:31.636424Z","iopub.status.idle":"2022-11-28T12:10:35.896286Z","shell.execute_reply.started":"2022-11-28T12:10:31.636394Z","shell.execute_reply":"2022-11-28T12:10:35.895265Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# model class\nclass MultiModel(torch.nn.Module):\n    def __init__(self):\n        super(MultiModel,self).__init__()\n        \n        self.config = AutoConfig.from_pretrained(modelName)\n        self.bert = AutoModel.from_pretrained(modelName, config = self.config)\n        \n        self.cnn_config = ViTConfig.from_pretrained(cnn_modelName)\n        self.vit = ViTModel.from_pretrained(cnn_modelName,config = self.cnn_config)\n        \n        self.fc = torch.nn.Sequential(\n            torch.nn.Linear(768+BERT_DIMENSION,30))\n        \n    def forward(self,input_ids,attention_mask,imgs):\n        pool_output = self.bert(input_ids,attention_mask = attention_mask)[1]\n        convOut = self.vit(pixel_values = imgs)[1]\n        \n        fcIn = torch.cat((pool_output,convOut),dim = 1)\n        fcOut = self.fc(fcIn)\n        return fcOut\n\nmodel = MultiModel()","metadata":{"execution":{"iopub.status.busy":"2022-11-28T12:10:35.899583Z","iopub.execute_input":"2022-11-28T12:10:35.899981Z","iopub.status.idle":"2022-11-28T12:10:47.117195Z","shell.execute_reply.started":"2022-11-28T12:10:35.899941Z","shell.execute_reply":"2022-11-28T12:10:47.116069Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"}]},{"cell_type":"code","source":"loss_fn = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)\n\nmodel = model.to(device)\n\n# Testing on the test data\ndef calAccuracy(model,dataloader,device):\n    correct = 0\n    total = 0\n    \n    torch.set_grad_enabled(False)\n    \n    for data in dataloader:\n        input_ids = data[\"input_ids\"].to(device)\n        attention_mask = data[\"attention_mask\"].to(device)\n        labels = data[\"labels\"].to(device)\n        imgs = data[\"img\"].to(device)\n        \n        total += input_ids.size(0)\n        \n        outputs = model(input_ids,attention_mask,imgs)\n        predicted = torch.nn.functional.softmax(outputs).argmax(1)\n        correct += (predicted==labels).sum().item()\n        \n    torch.set_grad_enabled(True)\n    finalAcc = (correct*100)/total\n    print(\"The accuracy of the model : \"+str(finalAcc))\n    return finalAcc","metadata":{"execution":{"iopub.status.busy":"2022-11-28T12:10:47.118920Z","iopub.execute_input":"2022-11-28T12:10:47.119699Z","iopub.status.idle":"2022-11-28T12:10:50.192142Z","shell.execute_reply.started":"2022-11-28T12:10:47.119651Z","shell.execute_reply":"2022-11-28T12:10:50.191067Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# training model function\ndef trainModel(model,dataloader,loss_fn,optimizer,EPOCHS,EPSILON,device,PATH):\n    \n    last_loss = (np.inf)/2\n    max_valAcc = 0\n    \n    optimizer.zero_grad()\n    for epoch in range(EPOCHS):\n        this_loss = 0.0\n\n        for idx,data in enumerate((dataloader)):\n            if(DEBUG and idx%100==0): print(\"Iteration : \"+str(idx))\n            \n            input_ids = data[\"input_ids\"].to(device)\n            attention_mask = data[\"attention_mask\"].to(device)\n            imgs = data[\"img\"].to(device)\n            labels = data[\"labels\"].to(device)\n            \n            output = model(input_ids,attention_mask,imgs)\n            loss = loss_fn(output,labels)\n            \n            (loss/gradAcc).backward()\n            \n            if (idx+1)%gradAcc == 0:\n                optimizer.step()\n                optimizer.zero_grad()\n\n            this_loss += loss\n        \n        this_loss = this_loss/len(dataloader)\n        #if(abs(this_loss-last_loss)<EPSILON): break\n        last_loss = this_loss\n        \n        print(\"Epoch : \"+str(epoch)+\", Loss ==> \"+str(last_loss))\n        print(\"Testing Accuracy ==>\")\n        \n        this_valAcc = calAccuracy(model,testloader,device)\n        if(this_valAcc>max_valAcc):\n            max_valAcc = this_valAcc\n            torch.save(model.state_dict(),PATH)\n            print(\"Model saved\")\n        \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-11-28T12:10:50.193616Z","iopub.execute_input":"2022-11-28T12:10:50.194606Z","iopub.status.idle":"2022-11-28T12:10:50.204693Z","shell.execute_reply.started":"2022-11-28T12:10:50.194554Z","shell.execute_reply":"2022-11-28T12:10:50.203733Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Running the loop\n\nPATH = \"/kaggle/working/Transformers+CNN.pth\"\ntrainModel(model,trainloader,loss_fn,optimizer,EPOCHS,EPSILON,device,PATH)","metadata":{"execution":{"iopub.status.busy":"2022-11-28T12:10:50.206513Z","iopub.execute_input":"2022-11-28T12:10:50.207340Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Iteration : 0\nIteration : 100\nIteration : 200\nIteration : 300\nIteration : 400\nIteration : 500\nIteration : 600\nIteration : 700\nIteration : 800\nIteration : 900\nIteration : 1000\nIteration : 1100\nIteration : 1200\nIteration : 1300\nIteration : 1400\nIteration : 1500\nIteration : 1600\nIteration : 1700\nIteration : 1800\nIteration : 1900\nIteration : 2000\nIteration : 2100\nIteration : 2200\nIteration : 2300\nIteration : 2400\nIteration : 2500\nIteration : 2600\nIteration : 2700\nIteration : 2800\nIteration : 2900\nIteration : 3000\nIteration : 3100\nIteration : 3200\nIteration : 3300\nIteration : 3400\nIteration : 3500\nIteration : 3600\nIteration : 3700\nIteration : 3800\nIteration : 3900\nIteration : 4000\nIteration : 4100\n","output_type":"stream"}]},{"cell_type":"code","source":"# reloading the last saved(best) model\nmodel = MultiModel()\nmodel.load_state_dict(torch.load(PATH))\nmodel.to(device)\n\n\n#print(\"Training Accuracy ==>\"+str(calAccuracy(model,trainloader,device)))\n#print(\"Testing Accuracy ==>\"+str(calAccuracy(model,testloader,device)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compDataset = bookDataset(\"comp_test_x.csv\",\"\",\"/kaggle/input/col774-2022/\",tokenizer)\ncomploader = DataLoader(compDataset,batch_size = BATCH_SIZE,shuffle = False)\n\n# printing the output dataframe to csv file\ndef outputToFile(model,dataloader,device,outFileName):\n    torch.set_grad_enabled(False)\n    \n    counter = 0\n    Ids = []\n    outputs = []\n    \n    for data in dataloader:\n        input_ids = data[\"input_ids\"].to(device)\n        attention_mask = data[\"attention_mask\"].to(device)\n        imgs = data[\"img\"].to(device)\n        model_outputs = model(input_ids,attention_mask,imgs)\n        predicted = torch.nn.functional.softmax(model_outputs).argmax(1)\n        \n        for pred in predicted:\n            Ids.append(counter)\n            outputs.append(int(pred))\n            counter += 1\n        \n    torch.set_grad_enabled(True)\n    df = pd.DataFrame(list(zip(Ids,outputs)),columns = [\"Id\",\"Genre\"])\n    df.to_csv(outFileName,index=False)\n\noutputToFile(model,comploader,device,\"/kaggle/working/transformer+cnn_submission.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}